{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Comparing OLPS algorithms on a diversified set of ETFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's compare the state of the art in OnLine Portfolio Selection (OLPS) algorithms and determine if they can enhance a rebalanced passive strategy in practice. [Online Portfolio Selection: A Survey by Bin Li and Steven C. H. Hoi](http://arxiv.org/abs/1212.2129) provides the most comprehensive review of multi-period portfolio allocation optimization algorithms.  The authors [developed](http://olps.stevenhoi.org/) the [OLPS Toolbox](  http://www.mysmu.edu.sg/faculty/chhoi/olps/OLPS_toolbox.pdf), but here we use [Mojmir Vinkler's](https://www.linkedin.com/profile/view?id=210899853) [implementation](https://github.com/Marigold/universal-portfolios)  and extend [his comparison](http://nbviewer.ipython.org/github/Marigold/universal-portfolios/blob/master/On-line%20portfolios.ipynb) to a more recent timeline with a set of ETFs to avoid survivorship bias (as suggested by [Ernie Chan](http://epchan.blogspot.cz/2007/01/universal-portfolios.html)) and idiosyncratic risk.\n",
    "\n",
    "Vinkler does all the hard work in his [thesis](http://is.muni.cz/th/358102/prif_m/?lang=en;id=183901), and concludes  that Universal Portfolios work practically the same as Constant Rebalanced Portfolios, and work better for an uncorrelated set of small and volatile stocks.  Here I'm looking to find if any strategy is applicable to a set of ETFs.\n",
    "\n",
    "The agorithms compared are:\n",
    "\n",
    "Type | Name | Algo | Reference \n",
    "-------------------------|------|------|----\n",
    "Benchmark | BAH | Buy and Hold |\n",
    "Benchmark | CRP | Constant Rebalanced Portfolio | T. Cover. [Universal Portfolios](http://www-isl.stanford.edu/~cover/papers/paper93.pdf), 1991.\n",
    "Benchmark | UCRP | Uniform CRP (UCRP), a special case of CRP with all weights being equal | T. Cover. [Universal Portfolios](http://www-isl.stanford.edu/~cover/papers/paper93.pdf), 1991.\n",
    "Benchmark | BCRP | Best Constant Rebalanced Portfolio | T. Cover. [Universal Portfolios](http://www-isl.stanford.edu/~cover/papers/paper93.pdf), 1991.\n",
    "Follow-the-Winner | UP | Universal Portfolio | T. Cover. [Universal Portfolios](http://www-isl.stanford.edu/~cover/papers/paper93.pdf), 1991.\n",
    "Follow-the-Winner | EG | Exponential Gradient |  Helmbold, David P., et al. [On‐Line Portfolio Selection Using Multiplicative Updates](http://www.cis.upenn.edu/~mkearns/finread/helmbold98line.pdf) Mathematical Finance 8.4 (1998): 325-347.\n",
    "Follow-the-Winner | ONS | Online Newton Step | A. Agarwal, E. Hazan, S. Kale, R. E. Schapire. [Algorithms for Portfolio Management based on the Newton Method](http://machinelearning.wustl.edu/mlpapers/paper_files/icml2006_AgarwalHKS06.pdf), 2006.\n",
    "Follow-the-Loser | Anticor | Anticorrelation | A. Borodin, R. El-Yaniv, and V. Gogan. [Can we learn to beat the best stock](http://arxiv.org/abs/1107.0036), 2005\n",
    "Follow-the-Loser |PAMR | Passive Aggressive Mean Reversion  |  B. Li, P. Zhao, S. C.H. Hoi, and V. Gopalkrishnan. [Pamr: Passive aggressive mean reversion strategy for portfolio selection](http://www.cais.ntu.edu.sg/~chhoi/paper_pdf/PAMR_ML_final.pdf), 2012.\n",
    "Follow-the-Loser |CWMR | Confidence Weighted Mean Reversion |  B. Li, S. C. H. Hoi, P. L. Zhao, and V. Gopalkrishnan.[Confidence weighted mean reversion strategy for online portfolio selection](http://jmlr.org/proceedings/papers/v15/li11b/li11b.pdf), 2013.        \n",
    "Follow-the-Loser | OLMAR | Online Moving Average Reversion| Bin Li and Steven C. H. Hoi [On-Line Portfolio Selection with Moving Average Reversion](http://arxiv.org/abs/1206.4626)\n",
    "Follow-the-Loser |RMR | Robust Median Reversion | D. Huang, J. Zhou, B. Li, S. C.vH. Hoi, S. Zhou [Robust Median Reversion Strategy for On-Line Portfolio Selection](http://ijcai.org/papers13/Papers/IJCAI13-296.pdf), 2013.\n",
    "Pattern Matching | Kelly | Kelly fractional betting |[Kelly Criterion](http://en.wikipedia.org/wiki/Kelly_criterion#Application_to_the_stock_market)\n",
    "Pattern Matching | BNN | nonparametric nearest neighbor log-optimal | L. Gyorfi, G. Lugosi, and F. Udina. [Nonparametric kernel based sequential investment strategies](http://papers.ssrn.com/sol3/papers.cfm?abstract_id=889976). Mathematical Finance 16 (2006) 337–357.\n",
    "Pattern Matching | CORN | correlation-driven nonparametric learning | B. Li, S. C. H. Hoi, and V. Gopalkrishnan. [Corn: correlation-driven nonparametric learning approach for portfolio selection](http://www.cais.ntu.edu.sg/~chhoi/paper_pdf/TIST-CORN.pdf), 2011.\n",
    "\n",
    "We pick 6 ETFs to avoid survivorship bias and capture broad market diversification. We select the longest running ETF per assset class: [VTI](https://www.google.com/finance?q=VTI), [EFA](https://www.google.com/finance?q=EFA), [EEM](https://www.google.com/finance?q=EFA), [TLT](https://www.google.com/finance?q=TLT), [TIP](https://www.google.com/finance?q=TIP), [VNQ](https://www.google.com/finance?q=VNQ) .  We train and select the best parameters on market data from 2005-2012 inclusive (8 years), and test on 2013-2014 inclusive (2 years). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You will first need to either download or install universal-portfolios from Vinkler\n",
    "# one way to do it is uncomment the line below and execute\n",
    "#!pip install --upgrade universal-portfolios \n",
    "# or\n",
    "#!pip install --upgrade -e git+git@github.com:Marigold/universal-portfolios.git@master#egg=universal-portfolios\n",
    "#\n",
    "# if the above fail, git clone git@github.com:marigold/universal-portfolios.git and python setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initialize and set debugging level to `debug` to track progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas_datareader import data as pdr\n",
    "# data reader now seperated to new package. pip install pandas-datareader\n",
    "#from pandas.io.data import DataReader\n",
    "import fix_yahoo_finance as yf\n",
    "yf.pdr_override() # <== that's all it takes :-)\n",
    "from datetime import datetime\n",
    "import six\n",
    "import universal as up\n",
    "from universal import tools\n",
    "from universal import algos\n",
    "import logging\n",
    "# we would like to see algos progress\n",
    "logging.basicConfig(format='%(asctime)s %(message)s', level=logging.DEBUG)\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rcParams['figure.figsize'] = (16, 10) # increase the size of graphs\n",
    "mpl.rcParams['legend.fontsize'] = 12\n",
    "mpl.rcParams['lines.linewidth'] = 1\n",
    "default_color_cycle = mpl.rcParams['axes.prop_cycle'] # save this as we will want it back later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# note what versions we are on:\n",
    "import sys\n",
    "print('Python: '+sys.version)\n",
    "print('Pandas: '+pd.__version__)\n",
    "import pkg_resources\n",
    "print('universal-portfolios: '+pkg_resources.get_distribution(\"universal-portfolios\").version)\n",
    "print('Numpy: '+np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We want to train on market data from 2005-2012 inclusive (8 years), and test on 2013-2014 inclusive (2 years). But at this point we accept the default parameters for the respective algorithms and we essentially are looking at two independent time periods.  In the future we will want to optimize the paramaters on the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load data from Yahoo\n",
    "# Be careful if you cange the order or types of ETFs to also change the CRP weight %'s in the swensen_allocation\n",
    "etfs = ['VTI', 'EFA', 'EEM', 'TLT', 'TIP', 'VNQ']\n",
    "#etfs = ['TLT','VNQ']\n",
    "# Swensen allocation from http://www.bogleheads.org/wiki/Lazy_portfolios#David_Swensen.27s_lazy_portfolio\n",
    "# as later updated here : https://www.yalealumnimagazine.com/articles/2398/david-swensen-s-guide-to-sleeping-soundly \n",
    "swensen_allocation = [0.3, 0.15, 0.1, 0.15, 0.15, 0.15]  \n",
    "benchmark = ['SPY']\n",
    "train_start = datetime(2005,1,1)#'2005-01-01'\n",
    "train_end   = datetime(2012,12,31)#'2012-12-31'\n",
    "test_start  = datetime(2013,1,1)#'2013-01-01'\n",
    "test_end    = datetime(2014,12,31)#'2014-12-31'\n",
    "#train = DataReader(etfs, 'yahoo', start=train_start, end=train_end)['Adj Close']\n",
    "#test  = DataReader(etfs, 'yahoo', start=test_start, end=test_end)['Adj Close']\n",
    "#train_b = DataReader(benchmark, 'yahoo', start=train_start, end=train_end)['Adj Close']\n",
    "#test_b  = DataReader(benchmark, 'yahoo', start=test_start, end=test_end)['Adj Close']\n",
    "train = pdr.get_data_yahoo(etfs, train_start, train_end)['Adj Close']\n",
    "test  = pdr.get_data_yahoo(etfs, test_start, test_end)['Adj Close']\n",
    "train_b = pdr.get_data_yahoo(benchmark, train_start, train_end)['Adj Close']\n",
    "test_b  = pdr.get_data_yahoo(benchmark, test_start, test_end)['Adj Close']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot normalized prices of the train set\n",
    "idx = pd.IndexSlice\n",
    "ax1 = (train / train.iloc[idx[0,:]]).plot()\n",
    "(train_b / train_b.iloc[idx[0,:]]).plot(ax=ax1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot normalized prices of the test set\n",
    "ax2 = (test / test.iloc[0,:]).plot()\n",
    "(test_b / test_b.iloc[0,:]).plot(ax=ax2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Comparing the Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to train on market data from a number of years, and test out of sample for a duration smaller than the train set. To get started we accept the default parameters for the respective algorithms and we essentially are just looking at two independent time periods.  In the future we will want to optimize the paramaters on the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#list all the algos\n",
    "olps_algos = [\n",
    "algos.Anticor(),\n",
    "algos.BAH(),\n",
    "algos.BCRP(),\n",
    "algos.BNN(),\n",
    "algos.CORN(),\n",
    "algos.CRP(b=swensen_allocation), # Non Uniform CRP (the Swensen allocation)\n",
    "algos.CWMR(),\n",
    "algos.EG(),\n",
    "algos.Kelly(),\n",
    "algos.OLMAR(),\n",
    "algos.ONS(),\n",
    "algos.PAMR(),\n",
    "algos.RMR()\n",
    "#algos.UP()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# put all the algos in a dataframe\n",
    "algo_names = [a.__class__.__name__ for a in olps_algos]\n",
    "algo_data = ['algo', 'results', 'profit', 'sharpe', 'information', 'annualized_return', 'drawdown_period','winning_pct']\n",
    "metrics = algo_data[2:]\n",
    "olps_train = pd.DataFrame(index=algo_names, columns=algo_data)\n",
    "olps_train.algo = olps_algos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we could train all the algos to find the best parameters for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run all algos - this takes more than a minute\n",
    "for name, alg in zip(olps_train.index, olps_train.algo):\n",
    "    olps_train.loc[name,'results'] = alg.run(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's make sure the fees are set to 0 at first\n",
    "for k, r in olps_train.results.iteritems():\n",
    "    r.fee = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we need 14 colors for the plot\n",
    "#n_lines = 14\n",
    "#color_idx = np.linspace(0, 1, n_lines)\n",
    "#mpl.rcParams['axes.color_cycle']=[plt.cm.rainbow(i) for i in color_idx]\n",
    "from cycler import cycler\n",
    "mpl.rcParams['axes.prop_cycle'] = cycler(color='bgrcmyk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot as if we had no fees\n",
    "# get the first result so we can grab the figure axes from the plot\n",
    "ax = olps_train.results[0].plot(assets=False, weights=False, ucrp=True, portfolio_label=olps_train.index[0])\n",
    "for k, r in olps_train.results.iteritems():\n",
    "    if k == olps_train.results.keys()[0]: # skip the first item because we have it already\n",
    "        continue\n",
    "    r.plot(assets=False, weights=False, ucrp=False, portfolio_label=k, ax=ax[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def olps_stats(df):\n",
    "    for name, r in df.results.iteritems():\n",
    "        df.ix[name,'profit'] = r.profit_factor\n",
    "        df.ix[name,'sharpe'] = r.sharpe\n",
    "        df.ix[name,'information'] = r.information\n",
    "        df.ix[name,'annualized_return'] = r.annualized_return * 100\n",
    "        df.ix[name,'drawdown_period'] = r.drawdown_period\n",
    "        df.ix[name,'winning_pct'] = r.winning_pct * 100\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "olps_stats(olps_train)\n",
    "olps_train[metrics].sort_values('profit', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's add fees of 0.1% per transaction (we pay $1 for every $1000 of stocks bought or sold).\n",
    "for k, r in olps_train.results.iteritems():\n",
    "    r.fee = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot with fees\n",
    "# get the first result so we can grab the figure axes from the plot\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "ax = olps_train.results[0].plot(assets=False, weights=False, ucrp=True, portfolio_label=olps_train.index[0])\n",
    "for k, r in olps_train.results.iteritems():\n",
    "    if k == olps_train.results.keys()[0]: # skip the first item because we have it already\n",
    "        continue\n",
    "    r.plot(assets=False, weights=False, ucrp=False, portfolio_label=k, ax=ax[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notice how Kelly crashes right away and how RMR and OLMAR float to the top after some high volatility.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "olps_stats(olps_train)\n",
    "olps_train[metrics].sort_values('profit', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run on the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create the test set dataframe\n",
    "olps_test  = pd.DataFrame(index=algo_names, columns=algo_data)\n",
    "olps_test.algo  = olps_algos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run all algos\n",
    "for name, alg in zip(olps_test.index, olps_test.algo):\n",
    "    olps_test.ix[name,'results'] = alg.run(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's make sure the fees are 0 at first\n",
    "for k, r in olps_test.results.iteritems():\n",
    "    r.fee = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot as if we had no fees\n",
    "# get the first result so we can grab the figure axes from the plot\n",
    "ax = olps_test.results[0].plot(assets=False, weights=False, ucrp=True, portfolio_label=olps_test.index[0])\n",
    "for k, r in olps_test.results.iteritems():\n",
    "    if k == olps_test.results.keys()[0]: # skip the first item because we have it already\n",
    "        continue\n",
    "    r.plot(assets=False, weights=False, ucrp=False, portfolio_label=k, ax=ax[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kelly went wild and crashed, so let's remove it from the mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot as if we had no fees\n",
    "# get the first result so we can grab the figure axes from the plot\n",
    "ax = olps_test.results[0].plot(assets=False, weights=False, ucrp=True, portfolio_label=olps_test.index[0])\n",
    "for k, r in olps_test.results.iteritems():\n",
    "    if k == olps_test.results.keys()[0] or k == 'Kelly': # skip the first item because we have it already\n",
    "        continue\n",
    "    r.plot(assets=False, weights=False, ucrp=False, portfolio_label=k, ax=ax[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "olps_stats(olps_test)\n",
    "olps_test[metrics].sort_values('profit', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wow, ONS and OLMAR are at the bottom of the list. Remember, we really didn't do any training, but if we had selected ONS or OLMAR at the beginning of 2013 based on past performance, we would not have beat BAH. Hm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Focusing on OLMAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Instead of using the default parameters, we will test several `window` parameters to see if we can get OLMAR to improve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we need need fewer colors so let's reset the colors_cycle\n",
    "mpl.rcParams['axes.prop_cycle']= default_color_cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_olmar = algos.OLMAR.run_combination(train, window=[3,5,10,15], eps=10)\n",
    "train_olmar.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(train_olmar.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_olmar = algos.OLMAR.run_combination(train, window=5, eps=[3,5,10,15])\n",
    "train_olmar.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(train_olmar.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### We find that a window of 5 and eps are 5 are optimal over the train time period, but the default of w=5 and eps=10 were also fine for our purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# OLMAR vs UCRP\n",
    "best_olmar = train_olmar[1]\n",
    "ax1 = best_olmar.plot(ucrp=True, bah=True, weights=False, assets=False, portfolio_label='OLMAR')\n",
    "olps_train.loc['CRP'].results.plot(ucrp=False, bah=False, weights=False, assets=False, ax=ax1[0], portfolio_label='CRP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On the train set OLMAR really delivers over CRP !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's print the stats\n",
    "print(best_olmar.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Let's see how individual ETFs contribute to portfolio equity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_olmar.plot_decomposition(legend=True, logy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's highlight the magnitude of the highest contributing ETF by removing the log scale and looking at it directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_olmar.plot_decomposition(legend=True, logy=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So VNQ (Real Estate) is the big driver after the market crash of 2008, which makes sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Let's look at portfolio allocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_olmar.plot(weights=True, assets=True, ucrp=False, logy=True, portfolio_label='OLMAR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### VNQ is the big driver of wealth (log scale). Let's test the strategy by removing the most profitable stock and comparing Total Wealth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find the name of the most profitable asset\n",
    "most_profitable = best_olmar.equity_decomposed.iloc[-1].argmax()\n",
    "\n",
    "# rerun algorithm on data without it\n",
    "result_without = algos.OLMAR().run(train.drop([most_profitable], 1))\n",
    "\n",
    "# and print results\n",
    "print(result_without.summary())\n",
    "result_without.plot(weights=False, assets=False, bah=True, ucrp=True, logy=True, portfolio_label='OLMAR-VNQ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_without.plot_decomposition(legend=True, logy=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Let's add fees of 0.1% per transaction (we pay \\$1 for every \\$1000 of stocks bought or sold)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_olmar.fee = 0.001\n",
    "print(best_olmar.summary())\n",
    "best_olmar.plot(weights=False, assets=False, bah=True, ucrp=True, logy=True, portfolio_label='OLMAR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### The results now fall, with a Sharpe Ratio below the ~0.5 market Sharpe, and an annualized return that has been cut in half due to fees. It's as if all the trading makes OLMAR underperform for the first 4 years until it can grab some volatility in 2008 to beat UCRP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at OLMAR in the test time frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_olmar = algos.OLMAR(window=5, eps=5).run(test)\n",
    "#print(train_olmar.summary())\n",
    "test_olmar.plot(ucrp=True, bah=True, weights=False, assets=False, portfolio_label='OLMAR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With fees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_olmar.fee = 0.001\n",
    "print(test_olmar.summary())\n",
    "test_olmar.plot(weights=False, assets=False, bah=True, ucrp=True, logy=True, portfolio_label='OLMAR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# OLMAR Starting in 2010"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The 2008-2009 recession was unique.  Let's try it all again starting in 2010, with a train set from 2010-2013 inclusive, and a test set of 2014."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set train and test time periods\n",
    "train_start_2010= datetime(2010,1,1)\n",
    "train_end_2010 = datetime(2013,12,31)\n",
    "test_start_2010 = datetime(2014,1,1)\n",
    "test_end_2010 = datetime(2014,12,31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data from Yahoo\n",
    "train_2010 = DataReader(etfs, 'yahoo', start=train_start_2010, end=train_end_2010)['Adj Close']\n",
    "test_2010  = DataReader(etfs, 'yahoo', start=test_start_2010,  end=test_end_2010)['Adj Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot normalized prices of these stocks\n",
    "(train_2010 / train_2010.iloc[0,:]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot normalized prices of these stocks\n",
    "(test_2010 / test_2010.iloc[0,:]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_olmar_2010 = algos.OLMAR().run(train_2010)\n",
    "train_crp_2010 = algos.CRP(b=swensen_allocation).run(train_2010)\n",
    "ax1 = train_olmar_2010.plot(assets=True, weights=False, ucrp=True, bah=True, portfolio_label='OLMAR')\n",
    "train_crp_2010.plot(ucrp=False, bah=False, weights=False, assets=False, ax=ax1[0], portfolio_label='CRP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(train_olmar_2010.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_olmar_2010.plot_decomposition(legend=True, logy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad, with a Sharpe at 1 and no one ETF dominating the portfolio.  Now let's see how it fairs in 2014. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_olmar_2010 = algos.OLMAR().run(test_2010)\n",
    "test_crp_2010 = algos.CRP(b=swensen_allocation).run(test_2010)\n",
    "ax1 = test_olmar_2010.plot(assets=True, weights=False, ucrp=True, bah=True, portfolio_label='OLMAR')\n",
    "test_crp_2010.plot(ucrp=False, bah=False, weights=False, assets=False, ax=ax1[0], portfolio_label='CRP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(test_olmar_2010.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just happen to be looking at a different time period and now the Sharpe drops below 0.5 and OLMAR fails to beat BAH.  Not good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_olmar_2010.plot_decomposition(legend=True, logy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# SPY / TLT portfolio comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's step back and simplify this by looking at OLMAR on a SPY and TLT portfolio.  We should also compare this portfolio to a rebalanced 70/30 mix of SPY and TLT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data from Yahoo\n",
    "spy_tlt_data = DataReader(['SPY', 'TLT'], 'yahoo', start=datetime(2010,1,1))['Adj Close']\n",
    "\n",
    "# plot normalized prices of these stocks\n",
    "(spy_tlt_data / spy_tlt_data.iloc[0,:]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spy_tlt_olmar_2010 = algos.OLMAR().run(spy_tlt_data)\n",
    "spy_tlt_olmar_2010.plot(assets=True, weights=True, ucrp=True, bah=True, portfolio_label='OLMAR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spy_tlt_olmar_2010.plot_decomposition(legend=True, logy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(spy_tlt_olmar_2010.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spy_tlt_2010 = algos.CRP(b=[0.7, 0.3]).run(spy_tlt_data)\n",
    "\n",
    "ax1 = spy_tlt_olmar_2010.plot(assets=False, weights=False, ucrp=True, bah=True, portfolio_label='OLMAR')\n",
    "spy_tlt_2010.plot(assets=False, weights=False, ucrp=False, bah=False, portfolio_label='CRP', ax=ax1[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Now OLMAR looks better!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLMAR Market Sectors comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's look at algo behavior on market sectors:\n",
    "\n",
    "- XLY Consumer Discrectionary SPDR Fund  \n",
    "- XLF Financial SPDR Fund  \n",
    "- XLK Technology SPDR Fund  \n",
    "- XLE Energy SPDR Fund  \n",
    "- XLV Health Care SPRD Fund  \n",
    "- XLI Industrial SPDR Fund  \n",
    "- XLP Consumer Staples SPDR Fund  \n",
    "- XLB Materials SPDR Fund  \n",
    "- XLU Utilities SPRD Fund  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sectors = ['XLY','XLF','XLK','XLE','XLV','XLI','XLP','XLB','XLU']\n",
    "train_sectors = DataReader(sectors, 'yahoo', start=train_start_2010, end=train_end_2010)['Adj Close']\n",
    "test_sectors  = DataReader(sectors, 'yahoo', start=test_start_2010,  end=test_end_2010)['Adj Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot normalized prices of these stocks\n",
    "(train_sectors / train_sectors.iloc[0,:]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot normalized prices of these stocks\n",
    "(test_sectors / test_sectors.iloc[0,:]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_olmar_sectors = algos.OLMAR().run(train_sectors)\n",
    "train_olmar_sectors.plot(assets=True, weights=False, ucrp=True, bah=True, portfolio_label='OLMAR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(train_olmar_sectors.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_olmar_sectors.plot(assets=False, weights=False, ucrp=True, bah=True, portfolio_label='OLMAR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_olmar_sectors = algos.OLMAR().run(test_sectors)\n",
    "test_olmar_sectors.plot(assets=True, weights=False, ucrp=True, bah=True, portfolio_label='OLMAR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_olmar_sectors = algos.OLMAR().run(test_sectors)\n",
    "test_olmar_sectors.plot(assets=False, weights=False, ucrp=True, bah=True, portfolio_label='OLMAR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All OLPS Algos Market Sectors comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#list all the algos\n",
    "olps_algos_sectors = [\n",
    "algos.Anticor(),\n",
    "algos.BAH(),\n",
    "algos.BCRP(),\n",
    "algos.BNN(),\n",
    "algos.CORN(),\n",
    "algos.CRP(),  # removed weights, and thus equivalent to UCRP\n",
    "algos.CWMR(),\n",
    "algos.EG(),\n",
    "algos.Kelly(),\n",
    "algos.OLMAR(),\n",
    "algos.ONS(),\n",
    "algos.PAMR(),\n",
    "algos.RMR(),\n",
    "algos.UP()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "olps_sectors_train = pd.DataFrame(index=algo_names, columns=algo_data)\n",
    "olps_sectors_train.algo = olps_algos_sectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run all algos - this takes more than a minute\n",
    "for name, alg in zip(olps_sectors_train.index, olps_sectors_train.algo):\n",
    "    olps_sectors_train.ix[name,'results'] = alg.run(train_sectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we need 14 colors for the plot\n",
    "n_lines = 14\n",
    "color_idx = np.linspace(0, 1, n_lines)\n",
    "mpl.rcParams['axes.color_cycle']=[plt.cm.rainbow(i) for i in color_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot as if we had no fees\n",
    "# get the first result so we can grab the figure axes from the plot\n",
    "olps_df = olps_sectors_train\n",
    "ax = olps_df.results[0].plot(assets=False, weights=False, ucrp=True, portfolio_label=olps_df.index[0])\n",
    "for k, r in olps_df.results.iteritems():\n",
    "    if k == olps_df.results.keys()[0]: # skip the first item because we have it already\n",
    "        continue\n",
    "    r.plot(assets=False, weights=False, ucrp=False, portfolio_label=k, ax=ax[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Kelly went wild, so let's remove it\n",
    "# get the first result so we can grab the figure axes from the plot\n",
    "olps_df = olps_sectors_train\n",
    "ax = olps_df.results[0].plot(assets=False, weights=False, ucrp=True, portfolio_label=olps_df.index[0])\n",
    "for k, r in olps_df.results.iteritems():\n",
    "    if k == olps_df.results.keys()[0] or k == 'Kelly' : # skip the first item because we have it already\n",
    "        continue\n",
    "    r.plot(assets=False, weights=False, ucrp=False, portfolio_label=k, ax=ax[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "olps_stats(olps_sectors_train)\n",
    "olps_sectors_train[metrics].sort_values('profit', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create the test set dataframe\n",
    "olps_sectors_test  = pd.DataFrame(index=algo_names, columns=algo_data)\n",
    "olps_sectors_test.algo  = olps_algos_sectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run all algos\n",
    "for name, alg in zip(olps_sectors_test.index, olps_sectors_test.algo):\n",
    "    olps_sectors_test.ix[name,'results'] = alg.run(test_sectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot as if we had no fees\n",
    "# get the first result so we can grab the figure axes from the plot\n",
    "olps_df = olps_sectors_test\n",
    "ax = olps_df.results[0].plot(assets=False, weights=False, ucrp=True, portfolio_label=olps_df.index[0])\n",
    "for k, r in olps_df.results.iteritems():\n",
    "    if k == olps_df.results.keys()[0] : #or k == 'Kelly': # skip the first item because we have it already\n",
    "        continue\n",
    "    r.plot(assets=False, weights=False, ucrp=False, portfolio_label=k, ax=ax[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop Kelly !\n",
    "# get the first result so we can grab the figure axes from the plot\n",
    "olps_df = olps_sectors_test\n",
    "ax = olps_df.results[0].plot(assets=False, weights=False, ucrp=True, portfolio_label=olps_df.index[0])\n",
    "for k, r in olps_df.results.iteritems():\n",
    "    if k == olps_df.results.keys()[0] or k == 'Kelly': # skip the first item because we have it already\n",
    "        continue\n",
    "    r.plot(assets=False, weights=False, ucrp=False, portfolio_label=k, ax=ax[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "olps_stats(olps_sectors_test)\n",
    "olps_sectors_test[metrics].sort_values('profit', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- More algo's could be optimized for parameters before they are run against the test set\n",
    "- In addition to the BAH, CRP and BCRP benchmarks, we could consider holding [SPY](https://www.google.com/finance?q=SPY) at 100% as a benchmark.\n",
    "- Could look into BAH(OLMAR) and other combinations as this framework supports combining approaches directly\n",
    "- Experiment with the ```run_subsets``` feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMR and OLMAR do add value to a Lazy Portfolio if tested or run over a long enough period of time.  This gives RMR and OLMAR a chance to grab onto a period of volatility.  But in an up market (2013-1014) you want to Follow-the-Leader, not Follow-the-Looser.  Of the other algo's, CRP or BAH are decent, and maybe it's worth understanding what ONS is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "name": "OLPS_Comparison.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
